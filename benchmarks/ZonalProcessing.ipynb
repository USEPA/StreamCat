{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from joblib import Parallel, delayed\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys \n",
    "parent_dir = os.path.abspath('..')\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "\n",
    "from stream_cat_config import (\n",
    "    LYR_DIR,\n",
    "    MASK_DIR_RP100,\n",
    "    MASK_DIR_SLP10,\n",
    "    MASK_DIR_SLP20,\n",
    "    ACCUM_DIR,\n",
    "    NHD_DIR,\n",
    "    OUT_DIR,\n",
    "    PCT_FULL_FILE,\n",
    "    PCT_FULL_FILE_RP100\n",
    ")\n",
    "\n",
    "from StreamCat_functions import (\n",
    "    PointInPoly,\n",
    "    createCatStats,\n",
    "    mask_points\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctl = pd.read_csv('../ControlTable_StreamCat.csv')\n",
    "inter_vpu = pd.read_csv(\"../InterVPU.csv\")\n",
    "INPUTS = np.load(ACCUM_DIR +\"/vpu_inputs.npy\", allow_pickle=True).item()\n",
    "\n",
    "already_processed = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict({'06': 'MS', '05': 'MS', '10U': 'MS', '10L': 'MS', '07': 'MS', '11': 'MS', '14': 'CO', '01': 'NE', '17': 'PN', '16': 'GB', '15': 'CO', '13': 'RG', '12': 'TX', '09': 'SR', '02': 'MA', '08': 'MS', '04': 'GL', '03W': 'SA', '03S': 'SA', '03N': 'SA', '18': 'CA'})\n",
      "21\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(INPUTS)\n",
    "print(len(INPUTS))\n",
    "print(len(ctl.loc[ctl['run'] == 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O:/PRIV/CPHEA/PESD/COR/CORFILES/Geospatial_Library_Projects/StreamCat/LandscapeRasters/Annual_NLCD_LndCov_1987_CU_C1V0.tif\n",
      "Acquiring `N_Human_Waste_1987` catchment statistics..."
     ]
    },
    {
     "ename": "RasterioIOError",
     "evalue": "O:/PRIV/CPHEA/PESD/COR/CORFILES/Geospatial_Library_Projects/StreamCat/LandscapeRasters/Annual_NLCD_LndCov_1987_CU_C1V0.tif: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"c:\\Users\\mweber\\AppData\\Local\\miniforge3\\envs\\xarray_spatial\\Lib\\site-packages\\xarray\\backends\\file_manager.py\", line 211, in _acquire_with_cache_info\n    file = self._cache[self._key]\n           ~~~~~~~~~~~^^^^^^^^^^^\n  File \"c:\\Users\\mweber\\AppData\\Local\\miniforge3\\envs\\xarray_spatial\\Lib\\site-packages\\xarray\\backends\\lru_cache.py\", line 56, in __getitem__\n    value = self._cache[key]\n            ~~~~~~~~~~~^^^^^\nKeyError: [<function open at 0x000002121740AD40>, ('O:/PRIV/CPHEA/PESD/COR/CORFILES/Geospatial_Library_Projects/StreamCat/LandscapeRasters/Annual_NLCD_LndCov_1987_CU_C1V0.tif',), 'r', (('sharing', False),), 'df85ee7c-aa62-46dd-b8cb-153bc03df006']\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"rasterio\\\\_base.pyx\", line 310, in rasterio._base.DatasetBase.__init__\n  File \"rasterio\\\\_base.pyx\", line 221, in rasterio._base.open_dataset\n  File \"rasterio\\\\_err.pyx\", line 359, in rasterio._err.exc_wrap_pointer\nrasterio._err.CPLE_OpenFailedError: O:/PRIV/CPHEA/PESD/COR/CORFILES/Geospatial_Library_Projects/StreamCat/LandscapeRasters/Annual_NLCD_LndCov_1987_CU_C1V0.tif: No such file or directory\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\mweber\\AppData\\Local\\miniforge3\\envs\\xarray_spatial\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 463, in _process_worker\n    r = call_item()\n        ^^^^^^^^^^^\n  File \"c:\\Users\\mweber\\AppData\\Local\\miniforge3\\envs\\xarray_spatial\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 291, in __call__\n    return self.fn(*self.args, **self.kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\mweber\\AppData\\Local\\miniforge3\\envs\\xarray_spatial\\Lib\\site-packages\\joblib\\parallel.py\", line 598, in __call__\n    return [func(*args, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\mweber\\AppData\\Local\\Temp\\ipykernel_45532\\1228123640.py\", line 53, in process_zone\n  File \"e:\\GitProjects\\StreamCat\\StreamCat_functions.py\", line 1120, in createCatStats\n    izd_array, ll_array = xarrayZonalStatsPrep(inZoneData, LandscapeLayer, use_dask)\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\GitProjects\\StreamCat\\StreamCat_functions.py\", line 1031, in xarrayZonalStatsPrep\n    ll_array = rioxarray.open_rasterio(landscape_layer_path).sel(band=1).drop_vars('band')\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\mweber\\AppData\\Local\\miniforge3\\envs\\xarray_spatial\\Lib\\site-packages\\rioxarray\\_io.py\", line 1128, in open_rasterio\n    riods = manager.acquire()\n            ^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\mweber\\AppData\\Local\\miniforge3\\envs\\xarray_spatial\\Lib\\site-packages\\xarray\\backends\\file_manager.py\", line 193, in acquire\n    file, _ = self._acquire_with_cache_info(needs_lock)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\mweber\\AppData\\Local\\miniforge3\\envs\\xarray_spatial\\Lib\\site-packages\\xarray\\backends\\file_manager.py\", line 217, in _acquire_with_cache_info\n    file = self._opener(*self._args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\mweber\\AppData\\Local\\miniforge3\\envs\\xarray_spatial\\Lib\\site-packages\\rasterio\\env.py\", line 463, in wrapper\n    return f(*args, **kwds)\n           ^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\mweber\\AppData\\Local\\miniforge3\\envs\\xarray_spatial\\Lib\\site-packages\\rasterio\\__init__.py\", line 356, in open\n    dataset = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"rasterio\\\\_base.pyx\", line 312, in rasterio._base.DatasetBase.__init__\nrasterio.errors.RasterioIOError: O:/PRIV/CPHEA/PESD/COR/CORFILES/Geospatial_Library_Projects/StreamCat/LandscapeRasters/Annual_NLCD_LndCov_1987_CU_C1V0.tif: No such file or directory\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRasterioIOError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 72\u001b[0m\n\u001b[0;32m     70\u001b[0m         cat\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mOUT_DIR\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow\u001b[38;5;241m.\u001b[39mFullTableName\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mzone\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     71\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 72\u001b[0m zone_results \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_zone\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mzone\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhydroregion\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mzone\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhydroregion\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mINPUTS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessed \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(INPUTS)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend_time\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos\u001b[38;5;241m.\u001b[39mcpu_count()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m parallel processes\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\mweber\\AppData\\Local\\miniforge3\\envs\\xarray_spatial\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mweber\\AppData\\Local\\miniforge3\\envs\\xarray_spatial\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mweber\\AppData\\Local\\miniforge3\\envs\\xarray_spatial\\Lib\\site-packages\\joblib\\parallel.py:1754\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_retrieval():\n\u001b[0;32m   1748\u001b[0m \n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[0;32m   1751\u001b[0m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[0;32m   1752\u001b[0m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aborting:\n\u001b[1;32m-> 1754\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1755\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1757\u001b[0m     \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m     \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mweber\\AppData\\Local\\miniforge3\\envs\\xarray_spatial\\Lib\\site-packages\\joblib\\parallel.py:1789\u001b[0m, in \u001b[0;36mParallel._raise_error_fast\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1785\u001b[0m \u001b[38;5;66;03m# If this error job exists, immediately raise the error by\u001b[39;00m\n\u001b[0;32m   1786\u001b[0m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[0;32m   1788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1789\u001b[0m     \u001b[43merror_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mweber\\AppData\\Local\\miniforge3\\envs\\xarray_spatial\\Lib\\site-packages\\joblib\\parallel.py:745\u001b[0m, in \u001b[0;36mBatchCompletionCallBack.get_result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    739\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel\u001b[38;5;241m.\u001b[39m_backend\n\u001b[0;32m    741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39msupports_retrieve_callback:\n\u001b[0;32m    742\u001b[0m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[0;32m    743\u001b[0m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[0;32m    744\u001b[0m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[1;32m--> 745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[0;32m    748\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\mweber\\AppData\\Local\\miniforge3\\envs\\xarray_spatial\\Lib\\site-packages\\joblib\\parallel.py:763\u001b[0m, in \u001b[0;36mBatchCompletionCallBack._return_or_raise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    762\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m TASK_ERROR:\n\u001b[1;32m--> 763\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[0;32m    764\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[0;32m    765\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;31mRasterioIOError\u001b[0m: O:/PRIV/CPHEA/PESD/COR/CORFILES/Geospatial_Library_Projects/StreamCat/LandscapeRasters/Annual_NLCD_LndCov_1987_CU_C1V0.tif: No such file or directory"
     ]
    }
   ],
   "source": [
    "# Parallel Cell\n",
    "\n",
    "for _, row in ctl.query(\"run == 1\").iterrows():\n",
    "    \n",
    "    apm = \"\" if row.AppendMetric == \"none\" else row.AppendMetric\n",
    "    if row.use_mask == 1:\n",
    "        mask_dir = MASK_DIR_RP100\n",
    "    elif row.use_mask == 2:\n",
    "        mask_dir = MASK_DIR_SLP10\n",
    "    elif row.use_mask == 3:\n",
    "        mask_dir = MASK_DIR_SLP20\n",
    "    else:\n",
    "        mask_dir = \"\"\n",
    "    # landscape_layer_year = re.findall(r'\\d+', row.LandscapeLayer)\n",
    "    actual_layer_name = row.LandscapeLayer\n",
    "    layer = (\n",
    "        actual_layer_name\n",
    "        if \"/\" in row.LandscapeLayer or \"\\\\\" in row.LandscapeLayer\n",
    "        else (f\"{LYR_DIR}/{actual_layer_name}\")\n",
    "    )  # use abspath\n",
    "    print(layer)\n",
    "    if isinstance(row.summaryfield, str):\n",
    "        summary = row.summaryfield.split(\";\")\n",
    "    else:\n",
    "        summary = None\n",
    "    if row.accum_type == \"Point\":\n",
    "        # Load in point geopandas table and Pct_Full table\n",
    "        # TODO: script to create this PCT_FULL_FILE\n",
    "        pct_full = pd.read_csv(\n",
    "            PCT_FULL_FILE if row.use_mask == 0 else PCT_FULL_FILE_RP100\n",
    "        )\n",
    "        points = gpd.read_file(layer)\n",
    "        if mask_dir:\n",
    "            points = mask_points(points, mask_dir, INPUTS)\n",
    "    # File string to store InterVPUs needed for adjustments\n",
    "    Connector = f\"{OUT_DIR}/{row.FullTableName}_connectors.csv\"\n",
    "    print(\n",
    "        f\"Acquiring `{row.FullTableName}` catchment statistics...\",\n",
    "        end=\"\",\n",
    "        flush=True,\n",
    "    )\n",
    "    #for zone, hydroregion in INPUTS.items():\n",
    "    def process_zone(zone, hydroregion):\n",
    "        if not os.path.exists(f\"{OUT_DIR}/{row.FullTableName}_{zone}.csv\"):\n",
    "            print(zone, end=\", \")\n",
    "            pre = f\"{NHD_DIR}/NHDPlus{hydroregion}/NHDPlus{zone}\"\n",
    "            if not row.accum_type == \"Point\":\n",
    "                izd = (\n",
    "                    f\"{mask_dir}/{zone}.tif\"\n",
    "                    if mask_dir\n",
    "                    else f\"{pre}/NHDPlusCatchment/cat\"\n",
    "                )\n",
    "                cat = createCatStats(\n",
    "                    row.accum_type,\n",
    "                    layer,\n",
    "                    izd,\n",
    "                    OUT_DIR,\n",
    "                    zone,\n",
    "                    row.by_RPU,\n",
    "                    mask_dir,\n",
    "                    NHD_DIR,\n",
    "                    hydroregion,\n",
    "                    apm,\n",
    "                )\n",
    "            if row.accum_type == \"Point\":\n",
    "                izd = f\"{pre}/NHDPlusCatchment/Catchment.shp\"\n",
    "                cat = PointInPoly(\n",
    "                    points, zone, izd, pct_full, mask_dir, apm, summary\n",
    "                )\n",
    "            cat.to_csv(f\"{OUT_DIR}/{row.FullTableName}_{zone}.csv\", index=False)\n",
    "    start_time = time.time()\n",
    "    zone_results = Parallel(n_jobs=16)(\n",
    "        delayed(process_zone) (zone, hydroregion) for zone, hydroregion in INPUTS.items()\n",
    "    )\n",
    "    end_time = time.time()\n",
    "    print(f\"Processed {len(INPUTS)} in {end_time - start_time} seconds with {os.cpu_count()} parallel processes\")\n",
    "    print(\"done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, row in ctl.query(\"run == 1\").iterrows():\n",
    "\n",
    "    apm = \"\" if row.AppendMetric == \"none\" else row.AppendMetric\n",
    "    if row.use_mask == 1:\n",
    "        mask_dir = MASK_DIR_RP100\n",
    "    elif row.use_mask == 2:\n",
    "        mask_dir = MASK_DIR_SLP10\n",
    "    elif row.use_mask == 3:\n",
    "        mask_dir = MASK_DIR_SLP20\n",
    "    else:\n",
    "        mask_dir = \"\"\n",
    "    landscape_layer_year = re.findall(r'\\d+', row.LandscapeLayer)\n",
    "    actual_layer_name = f\"Annual_NLCD_LndCov_{landscape_layer_year[0]}_CU_C1V0.tif\"\n",
    "    layer = (\n",
    "        actual_layer_name\n",
    "        if \"/\" in row.LandscapeLayer or \"\\\\\" in row.LandscapeLayer\n",
    "        else (f\"{LYR_DIR}/{actual_layer_name}\")\n",
    "    )  # use abspath\n",
    "    print(layer)\n",
    "    if isinstance(row.summaryfield, str):\n",
    "        summary = row.summaryfield.split(\";\")\n",
    "    else:\n",
    "        summary = None\n",
    "    if row.accum_type == \"Point\":\n",
    "        # Load in point geopandas table and Pct_Full table\n",
    "        # TODO: script to create this PCT_FULL_FILE\n",
    "        pct_full = pd.read_csv(\n",
    "            PCT_FULL_FILE if row.use_mask == 0 else PCT_FULL_FILE_RP100\n",
    "        )\n",
    "        points = gpd.read_file(layer)\n",
    "        if mask_dir:\n",
    "            points = mask_points(points, mask_dir, INPUTS)\n",
    "    # File string to store InterVPUs needed for adjustments\n",
    "    Connector = f\"{OUT_DIR}/{row.FullTableName}_connectors.csv\"\n",
    "    print(\n",
    "        f\"Acquiring `{row.FullTableName}` catchment statistics...\",\n",
    "        end=\"\",\n",
    "        flush=True,\n",
    "    )\n",
    "    start_time = time.time()\n",
    "    for zone, hydroregion in INPUTS.items():\n",
    "        if not os.path.exists(f\"{OUT_DIR}/{row.FullTableName}_{zone}.csv\"):\n",
    "            print(zone, end=\", \", flush=True)\n",
    "            pre = f\"{NHD_DIR}/NHDPlus{hydroregion}/NHDPlus{zone}\"\n",
    "            if not row.accum_type == \"Point\":\n",
    "                izd = (\n",
    "                    f\"{mask_dir}/{zone}.tif\"\n",
    "                    if mask_dir\n",
    "                    else f\"{pre}/NHDPlusCatchment/cat\"\n",
    "                )\n",
    "                cat = createCatStats(\n",
    "                    row.accum_type,\n",
    "                    layer,\n",
    "                    izd,\n",
    "                    OUT_DIR,\n",
    "                    zone,\n",
    "                    row.by_RPU,\n",
    "                    mask_dir,\n",
    "                    NHD_DIR,\n",
    "                    hydroregion,\n",
    "                    apm,\n",
    "                )\n",
    "            if row.accum_type == \"Point\":\n",
    "                izd = f\"{pre}/NHDPlusCatchment/Catchment.shp\"\n",
    "                cat = PointInPoly(\n",
    "                    points, zone, izd, pct_full, mask_dir, apm, summary\n",
    "                )\n",
    "            cat.to_csv(f\"{OUT_DIR}/{row.FullTableName}_{zone}.csv\", index=False)\n",
    "    end_time = time.time()\n",
    "    print(f\"Processed {len(INPUTS)} in {end_time-start_time} seconds using a for loop and one process\")\n",
    "    print(\"done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xarray_spatial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
