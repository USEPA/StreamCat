{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from joblib import Parallel, delayed\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ..stream_cat_config import (\n",
    "    LYR_DIR,\n",
    "    MASK_DIR_RP100,\n",
    "    MASK_DIR_SLP10,\n",
    "    MASK_DIR_SLP20,\n",
    "    ACCUM_DIR,\n",
    "    NHD_DIR,\n",
    "    OUT_DIR,\n",
    "    PCT_FULL_FILE,\n",
    "    PCT_FULL_FILE_RP100,\n",
    "    USER_ZONES,\n",
    ")\n",
    "\n",
    "from ..StreamCat_functions import (\n",
    "    Accumulation,\n",
    "    AdjustCOMs,\n",
    "    PointInPoly,\n",
    "    appendConnectors,\n",
    "    createCatStats,\n",
    "    interVPU,\n",
    "    makeNumpyVectors,\n",
    "    mask_points,\n",
    "    nhd_dict,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctl = pd.read_csv('../ControlTable_StreamCat.csv')\n",
    "inter_vpu = pd.read_csv(\"../InterVPU.csv\")\n",
    "INPUTS = np.load(ACCUM_DIR +\"/vpu_inputs.npy\", allow_pickle=True).item()\n",
    "\n",
    "already_processed = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, row in ctl.query(\"run == 1\").iterrows():\n",
    "\n",
    "    apm = \"\" if row.AppendMetric == \"none\" else row.AppendMetric\n",
    "    if row.use_mask == 1:\n",
    "        mask_dir = MASK_DIR_RP100\n",
    "    elif row.use_mask == 2:\n",
    "        mask_dir = MASK_DIR_SLP10\n",
    "    elif row.use_mask == 3:\n",
    "        mask_dir = MASK_DIR_SLP20\n",
    "    else:\n",
    "        mask_dir = \"\"\n",
    "    layer = (\n",
    "        row.LandscapeLayer\n",
    "        if \"/\" in row.LandscapeLayer or \"\\\\\" in row.LandscapeLayer\n",
    "        else (f\"{LYR_DIR}/{row.LandscapeLayer}\")\n",
    "    )  # use abspath\n",
    "    if isinstance(row.summaryfield, str):\n",
    "        summary = row.summaryfield.split(\";\")\n",
    "    else:\n",
    "        summary = None\n",
    "    if row.accum_type == \"Point\":\n",
    "        # Load in point geopandas table and Pct_Full table\n",
    "        # TODO: script to create this PCT_FULL_FILE\n",
    "        pct_full = pd.read_csv(\n",
    "            PCT_FULL_FILE if row.use_mask == 0 else PCT_FULL_FILE_RP100\n",
    "        )\n",
    "        points = gpd.read_file(layer)\n",
    "        if mask_dir:\n",
    "            points = mask_points(points, mask_dir, INPUTS)\n",
    "    # File string to store InterVPUs needed for adjustments\n",
    "    Connector = f\"{OUT_DIR}/{row.FullTableName}_connectors.csv\"\n",
    "    print(\n",
    "        f\"Acquiring `{row.FullTableName}` catchment statistics...\",\n",
    "        end=\"\",\n",
    "        flush=True,\n",
    "    )\n",
    "    #for zone, hydroregion in INPUTS.items():\n",
    "    def process_zone(zone, hydroregion):\n",
    "        if not os.path.exists(f\"{OUT_DIR}/{row.FullTableName}_{zone}.csv\"):\n",
    "            print(zone, end=\", \", flush=True)\n",
    "            pre = f\"{NHD_DIR}/NHDPlus{hydroregion}/NHDPlus{zone}\"\n",
    "            if not row.accum_type == \"Point\":\n",
    "                izd = (\n",
    "                    f\"{mask_dir}/{zone}.tif\"\n",
    "                    if mask_dir\n",
    "                    else f\"{pre}/NHDPlusCatchment/cat\"\n",
    "                )\n",
    "                cat = createCatStats(\n",
    "                    row.accum_type,\n",
    "                    layer,\n",
    "                    izd,\n",
    "                    OUT_DIR,\n",
    "                    zone,\n",
    "                    row.by_RPU,\n",
    "                    mask_dir,\n",
    "                    NHD_DIR,\n",
    "                    hydroregion,\n",
    "                    apm,\n",
    "                )\n",
    "            if row.accum_type == \"Point\":\n",
    "                izd = f\"{pre}/NHDPlusCatchment/Catchment.shp\"\n",
    "                cat = PointInPoly(\n",
    "                    points, zone, izd, pct_full, mask_dir, apm, summary\n",
    "                )\n",
    "            cat.to_csv(f\"{OUT_DIR}/{row.FullTableName}_{zone}.csv\", index=False)\n",
    "    start_time = time.time()\n",
    "    zone_results = Parallel(n_jobs=-1)(\n",
    "        delayed(process_zone) (zone, hydroregion) for zone, hydroregion in INPUTS.items()\n",
    "    )\n",
    "    end_time = time.time()\n",
    "    print(f\"Processed {len(INPUTS)} in {end_time - start_time} seconds with {os.cpu_count()} parallel processes\")\n",
    "    print(\"done!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
