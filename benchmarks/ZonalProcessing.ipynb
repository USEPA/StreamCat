{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from joblib import Parallel, delayed\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thudso02\\repositories\\parallel_streamcat\\StreamCat\\StreamCat_functions.py:1: SyntaxWarning: invalid escape sequence '\\/'\n",
      "  \"\"\"       __                                       __\n",
      "c:\\Users\\thudso02\\repositories\\parallel_streamcat\\StreamCat\\StreamCat_functions.py:1: SyntaxWarning: invalid escape sequence '\\/'\n",
      "  \"\"\"       __                                       __\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'osgeo'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 19\u001b[0m\n\u001b[0;32m      5\u001b[0m     sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(parent_dir)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstream_cat_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      8\u001b[0m     LYR_DIR,\n\u001b[0;32m      9\u001b[0m     MASK_DIR_RP100,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     16\u001b[0m     PCT_FULL_FILE_RP100\n\u001b[0;32m     17\u001b[0m )\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mStreamCat_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     20\u001b[0m     Accumulation,\n\u001b[0;32m     21\u001b[0m     AdjustCOMs,\n\u001b[0;32m     22\u001b[0m     PointInPoly,\n\u001b[0;32m     23\u001b[0m     appendConnectors,\n\u001b[0;32m     24\u001b[0m     createCatStats,\n\u001b[0;32m     25\u001b[0m     interVPU,\n\u001b[0;32m     26\u001b[0m     makeNumpyVectors,\n\u001b[0;32m     27\u001b[0m     mask_points,\n\u001b[0;32m     28\u001b[0m     nhd_dict,\n\u001b[0;32m     29\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\thudso02\\repositories\\parallel_streamcat\\StreamCat\\StreamCat_functions.py:31\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrasterio\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m#from gdalconst import *\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mosgeo\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gdal, ogr, osr\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrasterio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m transform\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rasterio\u001b[38;5;241m.\u001b[39m__version__[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'osgeo'"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import sys \n",
    "parent_dir = os.path.abspath('..')\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "\n",
    "from stream_cat_config import (\n",
    "    LYR_DIR,\n",
    "    MASK_DIR_RP100,\n",
    "    MASK_DIR_SLP10,\n",
    "    MASK_DIR_SLP20,\n",
    "    ACCUM_DIR,\n",
    "    NHD_DIR,\n",
    "    OUT_DIR,\n",
    "    PCT_FULL_FILE,\n",
    "    PCT_FULL_FILE_RP100\n",
    ")\n",
    "\n",
    "from StreamCat_functions import (\n",
    "    Accumulation,\n",
    "    AdjustCOMs,\n",
    "    PointInPoly,\n",
    "    appendConnectors,\n",
    "    createCatStats,\n",
    "    interVPU,\n",
    "    makeNumpyVectors,\n",
    "    mask_points,\n",
    "    nhd_dict,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctl = pd.read_csv('../ControlTable_StreamCat.csv')\n",
    "inter_vpu = pd.read_csv(\"../InterVPU.csv\")\n",
    "INPUTS = np.load(ACCUM_DIR +\"/vpu_inputs.npy\", allow_pickle=True).item()\n",
    "\n",
    "already_processed = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parallel Cell\n",
    "for _, row in ctl.query(\"run == 1\").iterrows():\n",
    "\n",
    "    apm = \"\" if row.AppendMetric == \"none\" else row.AppendMetric\n",
    "    if row.use_mask == 1:\n",
    "        mask_dir = MASK_DIR_RP100\n",
    "    elif row.use_mask == 2:\n",
    "        mask_dir = MASK_DIR_SLP10\n",
    "    elif row.use_mask == 3:\n",
    "        mask_dir = MASK_DIR_SLP20\n",
    "    else:\n",
    "        mask_dir = \"\"\n",
    "    layer = (\n",
    "        row.LandscapeLayer\n",
    "        if \"/\" in row.LandscapeLayer or \"\\\\\" in row.LandscapeLayer\n",
    "        else (f\"{LYR_DIR}/{row.LandscapeLayer}\")\n",
    "    )  # use abspath\n",
    "    if isinstance(row.summaryfield, str):\n",
    "        summary = row.summaryfield.split(\";\")\n",
    "    else:\n",
    "        summary = None\n",
    "    if row.accum_type == \"Point\":\n",
    "        # Load in point geopandas table and Pct_Full table\n",
    "        # TODO: script to create this PCT_FULL_FILE\n",
    "        pct_full = pd.read_csv(\n",
    "            PCT_FULL_FILE if row.use_mask == 0 else PCT_FULL_FILE_RP100\n",
    "        )\n",
    "        points = gpd.read_file(layer)\n",
    "        if mask_dir:\n",
    "            points = mask_points(points, mask_dir, INPUTS)\n",
    "    # File string to store InterVPUs needed for adjustments\n",
    "    Connector = f\"{OUT_DIR}/{row.FullTableName}_connectors.csv\"\n",
    "    print(\n",
    "        f\"Acquiring `{row.FullTableName}` catchment statistics...\",\n",
    "        end=\"\",\n",
    "        flush=True,\n",
    "    )\n",
    "    #for zone, hydroregion in INPUTS.items():\n",
    "    def process_zone(zone, hydroregion):\n",
    "        if not os.path.exists(f\"{OUT_DIR}/{row.FullTableName}_{zone}.csv\"):\n",
    "            print(zone, end=\", \", flush=True)\n",
    "            pre = f\"{NHD_DIR}/NHDPlus{hydroregion}/NHDPlus{zone}\"\n",
    "            if not row.accum_type == \"Point\":\n",
    "                izd = (\n",
    "                    f\"{mask_dir}/{zone}.tif\"\n",
    "                    if mask_dir\n",
    "                    else f\"{pre}/NHDPlusCatchment/cat\"\n",
    "                )\n",
    "                cat = createCatStats(\n",
    "                    row.accum_type,\n",
    "                    layer,\n",
    "                    izd,\n",
    "                    OUT_DIR,\n",
    "                    zone,\n",
    "                    row.by_RPU,\n",
    "                    mask_dir,\n",
    "                    NHD_DIR,\n",
    "                    hydroregion,\n",
    "                    apm,\n",
    "                )\n",
    "            if row.accum_type == \"Point\":\n",
    "                izd = f\"{pre}/NHDPlusCatchment/Catchment.shp\"\n",
    "                cat = PointInPoly(\n",
    "                    points, zone, izd, pct_full, mask_dir, apm, summary\n",
    "                )\n",
    "            cat.to_csv(f\"{OUT_DIR}/{row.FullTableName}_{zone}.csv\", index=False)\n",
    "    start_time = time.time()\n",
    "    zone_results = Parallel(n_jobs=-1)(\n",
    "        delayed(process_zone) (zone, hydroregion) for zone, hydroregion in INPUTS.items()\n",
    "    )\n",
    "    end_time = time.time()\n",
    "    print(f\"Processed {len(INPUTS)} in {end_time - start_time} seconds with {os.cpu_count()} parallel processes\")\n",
    "    print(\"done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, row in ctl.query(\"run == 1\").iterrows():\n",
    "\n",
    "    apm = \"\" if row.AppendMetric == \"none\" else row.AppendMetric\n",
    "    if row.use_mask == 1:\n",
    "        mask_dir = MASK_DIR_RP100\n",
    "    elif row.use_mask == 2:\n",
    "        mask_dir = MASK_DIR_SLP10\n",
    "    elif row.use_mask == 3:\n",
    "        mask_dir = MASK_DIR_SLP20\n",
    "    else:\n",
    "        mask_dir = \"\"\n",
    "    layer = (\n",
    "        row.LandscapeLayer\n",
    "        if \"/\" in row.LandscapeLayer or \"\\\\\" in row.LandscapeLayer\n",
    "        else (f\"{LYR_DIR}/{row.LandscapeLayer}\")\n",
    "    )  # use abspath\n",
    "    if isinstance(row.summaryfield, str):\n",
    "        summary = row.summaryfield.split(\";\")\n",
    "    else:\n",
    "        summary = None\n",
    "    if row.accum_type == \"Point\":\n",
    "        # Load in point geopandas table and Pct_Full table\n",
    "        # TODO: script to create this PCT_FULL_FILE\n",
    "        pct_full = pd.read_csv(\n",
    "            PCT_FULL_FILE if row.use_mask == 0 else PCT_FULL_FILE_RP100\n",
    "        )\n",
    "        points = gpd.read_file(layer)\n",
    "        if mask_dir:\n",
    "            points = mask_points(points, mask_dir, INPUTS)\n",
    "    # File string to store InterVPUs needed for adjustments\n",
    "    Connector = f\"{OUT_DIR}/{row.FullTableName}_connectors.csv\"\n",
    "    print(\n",
    "        f\"Acquiring `{row.FullTableName}` catchment statistics...\",\n",
    "        end=\"\",\n",
    "        flush=True,\n",
    "    )\n",
    "    start_time = time.time()\n",
    "    for zone, hydroregion in INPUTS.items():\n",
    "        if not os.path.exists(f\"{OUT_DIR}/{row.FullTableName}_{zone}.csv\"):\n",
    "            print(zone, end=\", \", flush=True)\n",
    "            pre = f\"{NHD_DIR}/NHDPlus{hydroregion}/NHDPlus{zone}\"\n",
    "            if not row.accum_type == \"Point\":\n",
    "                izd = (\n",
    "                    f\"{mask_dir}/{zone}.tif\"\n",
    "                    if mask_dir\n",
    "                    else f\"{pre}/NHDPlusCatchment/cat\"\n",
    "                )\n",
    "                cat = createCatStats(\n",
    "                    row.accum_type,\n",
    "                    layer,\n",
    "                    izd,\n",
    "                    OUT_DIR,\n",
    "                    zone,\n",
    "                    row.by_RPU,\n",
    "                    mask_dir,\n",
    "                    NHD_DIR,\n",
    "                    hydroregion,\n",
    "                    apm,\n",
    "                )\n",
    "            if row.accum_type == \"Point\":\n",
    "                izd = f\"{pre}/NHDPlusCatchment/Catchment.shp\"\n",
    "                cat = PointInPoly(\n",
    "                    points, zone, izd, pct_full, mask_dir, apm, summary\n",
    "                )\n",
    "            cat.to_csv(f\"{OUT_DIR}/{row.FullTableName}_{zone}.csv\", index=False)\n",
    "    end_time = time.time()\n",
    "    print(f\"Processed {len(INPUTS)} in {end_time-start_time} seconds using a for loop and one process\")\n",
    "    print(\"done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
